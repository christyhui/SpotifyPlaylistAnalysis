{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5616c659-99f5-43ee-b584-10f0a4df8f12",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05c0ea-850a-43b8-9e58-15df6df15c6e",
   "metadata": {},
   "source": [
    "One goal of this project is to work with the Spotify API and collect data on my own playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed83f94-8f21-4e01-a06b-4f1006c36a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import math\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30348293-7c49-40e5-b14f-d0584533b4bc",
   "metadata": {},
   "source": [
    "Safely load credentials to access the API so I have a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52735919-7c62-4861-8e94-6c9e08597ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1847f43b-f7df-4fac-8931-97c411ef68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth_manager = SpotifyOAuth(\n",
    "    client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"SPOTIFY_SECRET_ID\"),\n",
    "    redirect_uri=os.getenv(\"SPOTIFY_REDIRECT_URI\"),\n",
    "    scope=\"playlist-read-private playlist-read-collaborative\",\n",
    "    cache_path=\".spotify_cache\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7524f41-9409-45e7-9980-d34b7a61233c",
   "metadata": {},
   "source": [
    "Gather some data regarding my playlists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7401fc73-8b8d-4ed2-8781-8c2e5bc3ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_playlists = sp.current_user_playlists()\n",
    "all_playlists_items = all_playlists['items']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9324e3e-5f2e-4d83-aa12-c607930a4651",
   "metadata": {},
   "source": [
    "Define a function to grab tracks from one playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b6016a-7024-449f-bf4b-a5729fae1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tracks(playlist_id, playlist_name, playlist_owner=None):\n",
    "\n",
    "    # define empty list to store data in\n",
    "    all_tracks = []\n",
    "\n",
    "    # initialize max tracks i can grab per call\n",
    "    batch_size = 100\n",
    "\n",
    "    # control how often progress is printed\n",
    "    progress_interval = 100\n",
    "\n",
    "    # connect to api and gather total number of tracks so i know how many loops to do\n",
    "    try:\n",
    "        playlist_data = sp.playlist_tracks(playlist_id, limit=1)\n",
    "        total_tracks = playlist_data['total']\n",
    "    except spotipy.SpotifyException as e:\n",
    "        print(f\"Failed to retrieve playlist metadata for '{playlist_name}': {e}\")\n",
    "        return []\n",
    "\n",
    "    # calculate number of batches to do since each batch receives up to 100 tracks\n",
    "    num_batches = math.ceil(total_tracks / batch_size)\n",
    "\n",
    "    # loop through batches\n",
    "    for batch in range(num_batches):\n",
    "        \n",
    "        # tells which track the previous batch left off on\n",
    "        offset = batch * batch_size\n",
    "\n",
    "        # fetch tracks starting at offset \n",
    "        try:\n",
    "            track_page = sp.playlist_tracks(playlist_id, limit = batch_size, offset=offset)\n",
    "        except spotipy.SpotifyException as e:\n",
    "            print(f\"Error retrieving batch {batch + 1} of playlist '{playlist_name}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # iterates through each track in the batch \n",
    "        for item in track_page['items']:\n",
    "\n",
    "            # ensure loop does not stop if track is not available\n",
    "            track = item.get('track')\n",
    "            if not track or not track.get('id'):\n",
    "                continue\n",
    "\n",
    "            track_info = {\n",
    "                'playlist_id': playlist_id,\n",
    "                'playlist': playlist_name,\n",
    "                'playlist_owner': playlist_owner,\n",
    "                'track_id': track['id'],\n",
    "                'track_name': track['name'],\n",
    "                'track_duration': track['duration_ms'],\n",
    "                'explicit': track['explicit'],\n",
    "                'artist': [artist['name'] for artist in track['artists']],\n",
    "                'album': track['album']['name'],\n",
    "                'added_at': item['added_at']\n",
    "            }\n",
    "            all_tracks.append(track_info)\n",
    "\n",
    "        # shows progress of number of songs\n",
    "        processed = (batch + 1) * batch_size\n",
    "        if processed % progress_interval == 0 or batch == num_batches - 1:\n",
    "            print(f\"[{playlist_name}] Processed {min(processed, total_tracks)} / {total_tracks} tracks\")\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return all_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd0ae14-0303-49a2-a431-53e7104ee998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_playlists = all_playlists['total']\n",
    "total_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35389936-cba5-4781-aeb2-444ff7bd763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_from_all_playlists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4ec4b5-3107-4b0e-8265-498dafcc38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Plaliyst: CHOW MEIN CHICKEN FRIED RICE EGG ROLL BANGERS ONLYYYYYY\n",
      "[CHOW MEIN CHICKEN FRIED RICE EGG ROLL BANGERS ONLYYYYYY] Processed 23 / 23 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: Eeee deeee emmmmm\n",
      "[Eeee deeee emmmmm] Processed 12 / 12 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: warm souffl√© pancakes after yakiniku on a cold winter day\n",
      "[warm souffl√© pancakes after yakiniku on a cold winter day] Processed 100 / 155 tracks\n",
      "[warm souffl√© pancakes after yakiniku on a cold winter day] Processed 155 / 155 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: a ham sandwich, apple slices, and a caprisun at lunch time\n",
      "[a ham sandwich, apple slices, and a caprisun at lunch time] Processed 100 / 162 tracks\n",
      "[a ham sandwich, apple slices, and a caprisun at lunch time] Processed 162 / 162 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: chicken wraps in east los angeles\n",
      "[chicken wraps in east los angeles] Processed 64 / 64 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: tv dinners while playing neopets and lizzie mcguirre in the background\n",
      "[tv dinners while playing neopets and lizzie mcguirre in the background] Processed 50 / 50 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: Pok√©mon Lofi and Chill (2025)\n",
      "[Pok√©mon Lofi and Chill (2025)] Processed 100 / 334 tracks\n",
      "[Pok√©mon Lofi and Chill (2025)] Processed 200 / 334 tracks\n",
      "[Pok√©mon Lofi and Chill (2025)] Processed 300 / 334 tracks\n",
      "[Pok√©mon Lofi and Chill (2025)] Processed 334 / 334 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: cinammon sticks, freshly baked cookies, and nutmeg with your nose burning from the cold\n",
      "[cinammon sticks, freshly baked cookies, and nutmeg with your nose burning from the cold] Processed 19 / 19 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: creamy carbonara buldak ramen\n",
      "[creamy carbonara buldak ramen] Processed 100 / 158 tracks\n",
      "[creamy carbonara buldak ramen] Processed 158 / 158 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: baked pork chop with tomato sauce and rice at the hk diner \n",
      "[baked pork chop with tomato sauce and rice at the hk diner ] Processed 38 / 38 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: chinese oldies\n",
      "[chinese oldies] Processed 60 / 60 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: Pokemon Lofi üçÉ\n",
      "[Pokemon Lofi üçÉ] Processed 100 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 200 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 300 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 400 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 500 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 600 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 700 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 800 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 900 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1000 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1100 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1200 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1300 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1400 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1500 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1600 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1700 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1800 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 1900 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2000 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2100 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2200 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2300 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2400 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2500 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2600 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2700 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2800 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 2900 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 3000 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 3100 / 3142 tracks\n",
      "[Pokemon Lofi üçÉ] Processed 3142 / 3142 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: beef and broccoli, orange chicken, and burrito bowls at the university dorms\n",
      "[beef and broccoli, orange chicken, and burrito bowls at the university dorms] Processed 100 / 191 tracks\n",
      "[beef and broccoli, orange chicken, and burrito bowls at the university dorms] Processed 191 / 191 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "Fetching Plaliyst: succulent chinese meals served by the rudest 4'11 chinese woman imagineable\n",
      "[succulent chinese meals served by the rudest 4'11 chinese woman imagineable] Processed 29 / 29 tracks\n",
      "Moving onto Next Playlist...\n",
      "\n",
      "\n",
      "Success!!! All 4437 Tracks Have Been Extracted.\n"
     ]
    }
   ],
   "source": [
    "# use function now to loop over all my playlists\n",
    "for playlist in all_playlists_items:\n",
    "    playlist_id = playlist['id']\n",
    "    playlist_name = playlist['name']\n",
    "    playlist_owner = playlist['owner']['id']\n",
    "    \n",
    "    print(f\"Fetching Plaliyst: {playlist_name}\")\n",
    "    tracks_from_all_playlists.extend( get_all_tracks(playlist_id, playlist_name, playlist_owner) )\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    print(f\"Moving onto Next Playlist...\\n\")\n",
    "    \n",
    "print(f\"\\nSuccess!!! All {len(tracks_from_all_playlists)} Tracks Have Been Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ae95146-0189-4e17-b52f-c5fd4f6ff9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get playlists only created by me\n",
    "all_tracks = [tracks for tracks in tracks_from_all_playlists if tracks['playlist_owner'] == 'chrishui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f827113c-fecf-4a63-92ca-1f14e2432f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a6bb30-749d-47dc-bb15-87121202f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks = pd.DataFrame(all_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96094fb1-076e-4d58-8277-228a3e5d55a2",
   "metadata": {},
   "source": [
    "Rename tracks for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "388d2c20-7c0e-4f62-a029-bb8652392976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CHOW MEIN CHICKEN FRIED RICE EGG ROLL BANGERS ONLYYYYYY',\n",
       "       'Eeee deeee emmmmm',\n",
       "       'warm souffl√© pancakes after yakiniku on a cold winter day',\n",
       "       'a ham sandwich, apple slices, and a caprisun at lunch time',\n",
       "       'chicken wraps in east los angeles',\n",
       "       'tv dinners while playing neopets and lizzie mcguirre in the background',\n",
       "       'cinammon sticks, freshly baked cookies, and nutmeg with your nose burning from the cold',\n",
       "       'creamy carbonara buldak ramen',\n",
       "       'baked pork chop with tomato sauce and rice at the hk diner ',\n",
       "       'beef and broccoli, orange chicken, and burrito bowls at the university dorms',\n",
       "       \"succulent chinese meals served by the rudest 4'11 chinese woman imagineable\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tracks['playlist'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de283a13-b88b-4215-bd44-3c914eea8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {'CHOW MEIN CHICKEN FRIED RICE EGG ROLL BANGERS ONLYYYYYY' : 'OldChinese',\n",
    "      'Eeee deeee emmmmm': 'EDM',\n",
    "      'warm souffl√© pancakes after yakiniku on a cold winter day': 'Jpop',\n",
    "      'a ham sandwich, apple slices, and a caprisun at lunch time': 'Pop',\n",
    "      'chicken wraps in east los angeles': 'Rap',\n",
    "      'tv dinners while playing neopets and lizzie mcguirre in the background': 'OldPop',\n",
    "      'cinammon sticks, freshly baked cookies, and nutmeg with your nose burning from the cold': 'Christmas',\n",
    "      'creamy carbonara buldak ramen': 'Kpop',\n",
    "      'baked pork chop with tomato sauce and rice at the hk diner ': 'Cpop',\n",
    "      'beef and broccoli, orange chicken, and burrito bowls at the university dorms': 'Uni',\n",
    "      'succulent chinese meals served by the rudest 4\\'11 chinese woman imagineable': 'Chinese'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d06752a1-ce8b-42c1-9a61-b58f2a874472",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks['playlist'] = all_tracks['playlist'].map(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60135e4-68c2-464f-8d1b-1e1d7c3e21d2",
   "metadata": {},
   "source": [
    "**Please note I initially intended to use the Spotify API to pull all audio features for all tracks in my playlist. After a few failed attempts, I searched online for suggestions only to come across this [Spotify Web API update](https://developer.spotify.com/blog/2024-11-27-changes-to-the-web-api). Unfortunately, this means my original plan of using the `sp.audio_features()` endpoint would always fail, since it was deprecated. Solutions include using Reccobeats or SoundNet APIs, both which require downloading the songs (which may be illegal) or downloading the spotify 30-second song previews (which access through the API was also deprecated). The solution to this, unfortunately, was to use older datasets that include these audio features, perform an inner join, and hope the sample size is large enough.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ded717-bca0-4de6-97dd-fd83536deb15",
   "metadata": {},
   "source": [
    "The most comprehensive dataset is found [here](https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset?select=dataset.csv) and was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b864383-2d80-4a84-8322-79b7934f9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_sample = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9535ea-913e-45b9-807a-df133559b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name',\n",
       "       'popularity', 'duration_ms', 'explicit', 'danceability', 'energy',\n",
       "       'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
       "       'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature',\n",
       "       'track_genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c43f4-8adb-4648-92a0-fc9d5914b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_sample = tracks_sample.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "500578a7-efd1-4729-afa6-b6d4bdbdf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tracks = all_tracks.merge(tracks_sample, how = 'inner', on = 'track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf2e3b-5131-4fc2-b4fe-2f0aafe47bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e886d-ac9d-4ac1-94dc-1f332b7e6e11",
   "metadata": {},
   "source": [
    "**The resulting dataset gives 431 songs instead of the 901 I planned to initially work with. Although not ideal, this dataset is still rich and diverse enough to work with (hopefully).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b66d308-d065-40da-aadc-dc7a83f65e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tracks.to_csv(\"Data.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
